\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\abx@aux@refcontext{nty/global//global/global}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\BKM@entry[2]{}
\@input{./misc/titlepage.aux}
\babel@aux{english}{}
\pgfsyspdfmark {pgfid1}{18404377}{29591243}
\pgfsyspdfmark {pgfid4}{35323939}{29472815}
\pgfsyspdfmark {pgfid5}{37696676}{29225696}
\@input{./misc/self-assertion.aux}
\pgfsyspdfmark {pgfid6}{24293286}{22251698}
\pgfsyspdfmark {pgfid9}{35323939}{22244927}
\pgfsyspdfmark {pgfid10}{37696676}{21997808}
\@input{./misc/abstract.aux}
\abx@aux@cite{0}{DBLP:conf/nips/CunDS89}
\abx@aux@segm{0}{0}{DBLP:conf/nips/CunDS89}
\abx@aux@cite{0}{DBLP:conf/iclr/MolchanovTKAK17}
\abx@aux@segm{0}{0}{DBLP:conf/iclr/MolchanovTKAK17}
\abx@aux@cite{0}{han2016deepcompression}
\abx@aux@segm{0}{0}{han2016deepcompression}
\abx@aux@cite{0}{DBLP:journals/corr/HintonVD15}
\abx@aux@segm{0}{0}{DBLP:journals/corr/HintonVD15}
\abx@aux@cite{0}{DBLP:conf/icmlt/OkadoMIKS22}
\abx@aux@segm{0}{0}{DBLP:conf/icmlt/OkadoMIKS22}
\@input{./misc/abstract_de.aux}
\BKM@entry{id=1,dest={636861707465722E31},srcline={1}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{courbariaux2015binaryconnect}
\abx@aux@segm{0}{0}{courbariaux2015binaryconnect}
\abx@aux@cite{0}{courbariaux2015binaryconnect}
\abx@aux@segm{0}{0}{courbariaux2015binaryconnect}
\abx@aux@cite{0}{rastegari2016xnor}
\abx@aux@segm{0}{0}{rastegari2016xnor}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:chapter1}{{1}{1}{Introduction}{chapter.1}{}}
\BKM@entry{id=2,dest={636861707465722E32},srcline={1}}{5C3337365C3337375C303030425C303030615C303030635C3030306B5C303030675C303030725C3030306F5C303030755C3030306E5C30303064}
\BKM@entry{id=3,dest={73656374696F6E2E322E31},srcline={16}}{5C3337365C3337375C303030465C303030755C3030306E5C303030645C303030615C3030306D5C303030655C3030306E5C303030745C303030615C3030306C5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C30303067}
\BKM@entry{id=4,dest={73756273656374696F6E2E322E312E31},srcline={23}}{5C3337365C3337375C303030445C303030655C3030306E5C303030735C303030655C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:chapter2}{{2}{3}{Background}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Fundamentals of Deep Learning}{3}{section.2.1}\protected@file@percent }
\newlabel{sec:deeplearning}{{2.1}{3}{Fundamentals of Deep Learning}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Dense and Convolutional Layers}{3}{subsection.2.1.1}\protected@file@percent }
\newlabel{subsec:denseconvolutional}{{2.1.1}{3}{Dense and Convolutional Layers}{subsection.2.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces An example of a NN with two hidden dense layers, showing the connections between neurons in adjacent layers.}}{4}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:dense_layer}{{2.1}{4}{An example of a NN with two hidden dense layers, showing the connections between neurons in adjacent layers}{figure.caption.4}{}}
\abx@aux@cite{0}{gholami2021survey}
\abx@aux@segm{0}{0}{gholami2021survey}
\abx@aux@cite{0}{hubara2016qnn}
\abx@aux@segm{0}{0}{hubara2016qnn}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A 3×3 kernel (filter) sliding over a padded input matrix to compute the output feature map, demonstrating the interaction between the kernel weights and input values at a specific position.}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:convolution}{{2.2}{5}{A 3×3 kernel (filter) sliding over a padded input matrix to compute the output feature map, demonstrating the interaction between the kernel weights and input values at a specific position}{figure.caption.5}{}}
\abx@aux@cite{0}{huang2017densely}
\abx@aux@segm{0}{0}{huang2017densely}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces A 3×3x3 kernel (filter) sliding over an RGB input matrix to produce a single-channeled output feature map.}}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:convolution_multiple_channels}{{2.3}{6}{A 3×3x3 kernel (filter) sliding over an RGB input matrix to produce a single-channeled output feature map}{figure.caption.6}{}}
\BKM@entry{id=5,dest={73756273656374696F6E2E322E312E32},srcline={135}}{5C3337365C3337375C3030304C5C3030306F5C303030735C303030735C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=6,dest={73756273656374696F6E2E322E312E33},srcline={179}}{5C3337365C3337375C303030465C3030306F5C303030725C303030775C303030615C303030725C303030645C3030302D5C303030505C303030615C303030735C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030425C303030615C303030635C3030306B5C3030302D5C303030505C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Loss Functions and Regularization}{7}{subsection.2.1.2}\protected@file@percent }
\newlabel{subsec:lossregularization}{{2.1.2}{7}{Loss Functions and Regularization}{subsection.2.1.2}{}}
\BKM@entry{id=7,dest={73656374696F6E2E322E32},srcline={223}}{5C3337365C3337375C303030425C303030615C303030735C303030695C303030635C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030515C303030755C303030615C3030306E5C303030745C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=8,dest={73756273656374696F6E2E322E322E31},srcline={229}}{5C3337365C3337375C303030505C303030755C303030725C303030705C3030306F5C303030735C303030655C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030445C303030655C303030665C303030695C3030306E5C303030695C303030745C303030695C3030306F5C3030306E}
\abx@aux@cite{0}{DBLP:journals/corr/abs-2111-00364}
\abx@aux@segm{0}{0}{DBLP:journals/corr/abs-2111-00364}
\abx@aux@cite{0}{DBLP:journals/csi/RegueroMV25}
\abx@aux@segm{0}{0}{DBLP:journals/csi/RegueroMV25}
\abx@aux@cite{0}{rastegari2016xnor}
\abx@aux@segm{0}{0}{rastegari2016xnor}
\abx@aux@cite{0}{DBLP:conf/eccv/ZhangYYH18}
\abx@aux@segm{0}{0}{DBLP:conf/eccv/ZhangYYH18}
\abx@aux@cite{0}{DBLP:conf/codit/KhalifaM24}
\abx@aux@segm{0}{0}{DBLP:conf/codit/KhalifaM24}
\abx@aux@cite{0}{DBLP:journals/corr/abs-2105-13331}
\abx@aux@segm{0}{0}{DBLP:journals/corr/abs-2105-13331}
\abx@aux@cite{0}{DBLP:journals/corr/abs-2404-05639}
\abx@aux@segm{0}{0}{DBLP:journals/corr/abs-2404-05639}
\abx@aux@cite{0}{gray1998quantization}
\abx@aux@segm{0}{0}{gray1998quantization}
\abx@aux@cite{0}{gholami2021survey}
\abx@aux@segm{0}{0}{gholami2021survey}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Forward-Pass and Back-Propagation}{8}{subsection.2.1.3}\protected@file@percent }
\newlabel{subsec:forwardback}{{2.1.3}{8}{Forward-Pass and Back-Propagation}{subsection.2.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Basics of Quantization}{8}{section.2.2}\protected@file@percent }
\newlabel{sec:basicsofquantization}{{2.2}{8}{Basics of Quantization}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Purpose and Definition}{8}{subsection.2.2.1}\protected@file@percent }
\newlabel{subsec:purposeanddefinition}{{2.2.1}{8}{Purpose and Definition}{subsection.2.2.1}{}}
\BKM@entry{id=9,dest={73756273656374696F6E2E322E322E32},srcline={278}}{5C3337365C3337375C303030435C3030306F5C303030725C303030655C3030305C3034305C303030515C303030755C303030615C3030306E5C303030745C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030615C303030635C303030685C303030655C30303073}
\abx@aux@cite{0}{Edouard2022SPIQ}
\abx@aux@segm{0}{0}{Edouard2022SPIQ}
\abx@aux@cite{0}{jiang2021efficient}
\abx@aux@segm{0}{0}{jiang2021efficient}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Core Quantization Approaches}{9}{subsection.2.2.2}\protected@file@percent }
\newlabel{subsec:commonquantizationapproaches}{{2.2.2}{9}{Core Quantization Approaches}{subsection.2.2.2}{}}
\abx@aux@cite{0}{DBLP:journals/tnn/GyselPMG18}
\abx@aux@segm{0}{0}{DBLP:journals/tnn/GyselPMG18}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces An example illustrating the quantization operation on the weight matrix from Figure \ref {fig:dense_layer}, with arbitrary values for demonstration purposes.}}{10}{figure.caption.7}\protected@file@percent }
\newlabel{fig:quantizing_example}{{2.4}{10}{An example illustrating the quantization operation on the weight matrix from Figure \ref {fig:dense_layer}, with arbitrary values for demonstration purposes}{figure.caption.7}{}}
\abx@aux@cite{0}{gholami2021survey}
\abx@aux@segm{0}{0}{gholami2021survey}
\abx@aux@cite{0}{DBLP:journals/corr/abs-2101-05615}
\abx@aux@segm{0}{0}{DBLP:journals/corr/abs-2101-05615}
\BKM@entry{id=10,dest={73656374696F6E2E322E33},srcline={365}}{5C3337365C3337375C3030304C5C303030655C303030615C303030725C3030306E5C303030655C303030645C3030305C3034305C303030515C303030755C303030615C3030306E5C303030745C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces  An example illustrating min-max quantization of input data to 8 bits, followed by matrix multiplication with the quantized weight matrix from Figure \ref {fig:quantizing_example}. Input data has arbitrary values for demonstration purposes.}}{11}{figure.caption.8}\protected@file@percent }
\newlabel{fig:min_max_quantization}{{2.5}{11}{An example illustrating min-max quantization of input data to 8 bits, followed by matrix multiplication with the quantized weight matrix from Figure \ref {fig:quantizing_example}. Input data has arbitrary values for demonstration purposes}{figure.caption.8}{}}
\BKM@entry{id=11,dest={73756273656374696F6E2E322E332E31},srcline={374}}{5C3337365C3337375C303030545C303030725C303030615C303030645C303030655C3030302D5C3030306F5C303030665C303030665C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030435C303030685C303030615C3030306C5C3030306C5C303030655C3030306E5C303030675C303030655C30303073}
\abx@aux@cite{0}{DBLP:conf/eccv/ZhangYYH18}
\abx@aux@segm{0}{0}{DBLP:conf/eccv/ZhangYYH18}
\abx@aux@cite{0}{DBLP:conf/iclr/EsserMBAM20}
\abx@aux@segm{0}{0}{DBLP:conf/iclr/EsserMBAM20}
\abx@aux@cite{0}{DBLP:conf/eccv/ParkYV18}
\abx@aux@segm{0}{0}{DBLP:conf/eccv/ParkYV18}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces A demonstration of the varying application of scaling factors, ranging from a single scalar applied to the entire kernel (1) to separate scalars assigned to spatial dimensions (e.g., 1, 2), channels (4), filters (9), and other granular configurations.}}{12}{figure.caption.9}\protected@file@percent }
\newlabel{fig:granularity-conv2d}{{2.6}{12}{A demonstration of the varying application of scaling factors, ranging from a single scalar applied to the entire kernel (1) to separate scalars assigned to spatial dimensions (e.g., 1, 2), channels (4), filters (9), and other granular configurations}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Learned Quantization}{12}{section.2.3}\protected@file@percent }
\newlabel{sec:section3}{{2.3}{12}{Learned Quantization}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Trade-offs and Challenges}{12}{subsection.2.3.1}\protected@file@percent }
\newlabel{subsec:subsection1}{{2.3.1}{12}{Trade-offs and Challenges}{subsection.2.3.1}{}}
\BKM@entry{id=12,dest={73756273656374696F6E2E322E332E32},srcline={430}}{5C3337365C3337375C303030435C3030306F5C3030306D5C3030306D5C3030306F5C3030306E5C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C303030645C30303073}
\abx@aux@cite{0}{bengio2013estimating}
\abx@aux@segm{0}{0}{bengio2013estimating}
\abx@aux@cite{0}{fan2021training}
\abx@aux@segm{0}{0}{fan2021training}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Common Methods}{13}{subsection.2.3.2}\protected@file@percent }
\newlabel{subsec:commonlearnedquantizationmethods}{{2.3.2}{13}{Common Methods}{subsection.2.3.2}{}}
\abx@aux@cite{0}{DBLP:journals/jstsp/Chen0ZHY20}
\abx@aux@segm{0}{0}{DBLP:journals/jstsp/Chen0ZHY20}
\abx@aux@cite{0}{jacob2018quantization}
\abx@aux@segm{0}{0}{jacob2018quantization}
\abx@aux@cite{0}{DBLP:conf/cvpr/JungSLSHKHC19}
\abx@aux@segm{0}{0}{DBLP:conf/cvpr/JungSLSHKHC19}
\abx@aux@cite{0}{DBLP:conf/iclr/EsserMBAM20}
\abx@aux@segm{0}{0}{DBLP:conf/iclr/EsserMBAM20}
\abx@aux@cite{0}{DBLP:conf/eccv/ZhangYYH18}
\abx@aux@segm{0}{0}{DBLP:conf/eccv/ZhangYYH18}
\BKM@entry{id=13,dest={636861707465722E33},srcline={1}}{5C3337365C3337375C3030304C5C303030655C303030615C303030725C3030306E5C303030655C303030645C3030305C3034305C303030515C303030755C303030615C3030306E5C303030745C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030535C303030635C303030685C303030655C3030306D5C303030655C30303073}
\BKM@entry{id=14,dest={73656374696F6E2E332E31},srcline={11}}{5C3337365C3337375C3030304E5C303030655C303030735C303030745C303030655C303030645C3030305C3034305C303030515C303030755C303030615C3030306E5C303030745C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030304C5C303030615C303030795C303030655C30303072}
\BKM@entry{id=15,dest={73756273656374696F6E2E332E312E31},srcline={22}}{5C3337365C3337375C303030435C3030306F5C303030725C303030655C3030305C3034305C3030304C5C3030306F5C303030675C303030695C303030635C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030535C303030745C303030725C303030755C303030635C303030745C303030755C303030725C30303065}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Learned Quantization Schemes}{15}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:chapter3}{{3}{15}{Learned Quantization Schemes}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Nested Quantization Layer}{15}{section.3.1}\protected@file@percent }
\newlabel{sec:nestedquantizationlayer}{{3.1}{15}{Nested Quantization Layer}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Core Logic and Structure}{15}{subsection.3.1.1}\protected@file@percent }
\newlabel{subsec:quantizedconvolutional}{{3.1.1}{15}{Core Logic and Structure}{subsection.3.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces A standard convolutional layer (left) and its integration with the nested quantization layer (right) for both weights and bias. Quantization logic is applied to weights and biases during the forward pass, with trainable scaling factors updated using custom gradients in the backward pass. Parameter gradients are passed downward as is.}}{16}{figure.caption.10}\protected@file@percent }
\newlabel{fig:nested_quantization}{{3.1}{16}{A standard convolutional layer (left) and its integration with the nested quantization layer (right) for both weights and bias. Quantization logic is applied to weights and biases during the forward pass, with trainable scaling factors updated using custom gradients in the backward pass. Parameter gradients are passed downward as is}{figure.caption.10}{}}
\BKM@entry{id=16,dest={73756273656374696F6E2E332E312E32},srcline={92}}{5C3337365C3337375C3030304C5C303030655C303030615C303030725C3030306E5C303030655C303030645C3030305C3034305C303030535C303030635C303030615C3030306C5C303030655C3030305C3034305C303030465C303030615C303030635C303030745C3030306F5C30303072}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A demonstration of the varying applications of scaling factors, ranging from a single scalar applied to the entire weight matrix (1) to row-wise and column-wise application of vector scalers.}}{17}{figure.caption.11}\protected@file@percent }
\newlabel{fig:scaler-application-dense}{{3.2}{17}{A demonstration of the varying applications of scaling factors, ranging from a single scalar applied to the entire weight matrix (1) to row-wise and column-wise application of vector scalers}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Learned Scale Factor}{17}{subsection.3.1.2}\protected@file@percent }
\newlabel{subsec:learnedscalefactor}{{3.1.2}{17}{Learned Scale Factor}{subsection.3.1.2}{}}
\BKM@entry{id=17,dest={73656374696F6E2E332E32},srcline={204}}{5C3337365C3337375C303030435C303030755C303030735C303030745C3030306F5C3030306D5C3030305C3034305C3030304C5C3030306F5C303030735C303030735C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030545C303030655C303030725C3030306D5C30303073}
\BKM@entry{id=18,dest={73756273656374696F6E2E332E322E31},srcline={214}}{5C3337365C3337375C303030445C303030655C303030735C303030695C303030675C3030306E5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030495C3030306E5C303030745C303030655C303030675C303030725C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=19,dest={73756273656374696F6E2E332E322E32},srcline={262}}{5C3337365C3337375C3030304C5C3030306F5C303030735C303030735C3030305C3034305C303030545C303030655C303030725C3030306D5C3030305C3034305C303030445C303030655C303030665C303030695C3030306E5C303030695C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Custom Loss Function Terms}{19}{section.3.2}\protected@file@percent }
\newlabel{sec:customloss}{{3.2}{19}{Custom Loss Function Terms}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Design and Integration}{19}{subsection.3.2.1}\protected@file@percent }
\newlabel{subsec:designandintegration}{{3.2.1}{19}{Design and Integration}{subsection.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces An illustration of how a custom loss term, incorporating layer parameters and scale factors, integrates into the training process.}}{20}{figure.caption.12}\protected@file@percent }
\newlabel{fig:custom_loss_term_integration}{{3.3}{20}{An illustration of how a custom loss term, incorporating layer parameters and scale factors, integrates into the training process}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Loss Term Definitions}{20}{subsection.3.2.2}\protected@file@percent }
\newlabel{subsec:losstermdefinitions}{{3.2.2}{20}{Loss Term Definitions}{subsection.3.2.2}{}}
\BKM@entry{id=20,dest={636861707465722E34},srcline={1}}{5C3337365C3337375C303030455C303030785C303030705C303030655C303030725C303030695C3030306D5C303030655C3030306E5C303030745C30303073}
\abx@aux@cite{0}{lecun2010mnist}
\abx@aux@segm{0}{0}{lecun2010mnist}
\abx@aux@cite{0}{krizhevsky2009learning}
\abx@aux@segm{0}{0}{krizhevsky2009learning}
\abx@aux@cite{0}{DBLP:journals/information/HowardG20}
\abx@aux@segm{0}{0}{DBLP:journals/information/HowardG20}
\BKM@entry{id=21,dest={73656374696F6E2E342E31},srcline={15}}{5C3337365C3337375C303030455C303030785C303030705C303030655C303030725C303030695C3030306D5C303030655C3030306E5C303030745C303030615C3030306C5C3030305C3034305C303030535C303030655C303030745C303030755C30303070}
\BKM@entry{id=22,dest={73656374696F6E2E342E32},srcline={64}}{5C3337365C3337375C3030304F5C303030705C303030745C303030695C3030306D5C303030615C3030306C5C3030305C3034305C303030545C303030685C303030725C303030655C303030735C303030685C3030306F5C3030306C5C303030645C303030735C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304E5C303030655C303030735C303030745C303030655C303030645C3030305C3034305C303030515C303030755C303030615C3030306E5C303030745C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiments}{21}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:chapter4}{{4}{21}{Experiments}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Experimental Setup}{21}{section.4.1}\protected@file@percent }
\newlabel{sec:setup}{{4.1}{21}{Experimental Setup}{section.4.1}{}}
\BKM@entry{id=23,dest={73756273656374696F6E2E342E322E31},srcline={70}}{5C3337365C3337375C303030465C303030755C3030306C5C3030306C5C303030795C3030305C3034305C303030435C3030306F5C3030306E5C3030306E5C303030655C303030635C303030745C303030655C303030645C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Network Settings for Different Datasets}}{22}{table.caption.13}\protected@file@percent }
\newlabel{tab:hyperparameters}{{4.1}{22}{Network Settings for Different Datasets}{table.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Optimal Thresholds for Nested Quantization Layers}{22}{section.4.2}\protected@file@percent }
\newlabel{sec:paretofronts}{{4.2}{22}{Optimal Thresholds for Nested Quantization Layers}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Fully Connected Layers}{22}{subsection.4.2.1}\protected@file@percent }
\newlabel{subsec:paretofrontsdense}{{4.2.1}{22}{Fully Connected Layers}{subsection.4.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Scale Factor Granularity}}{22}{table.caption.14}\protected@file@percent }
\newlabel{tab:scalefactorgranularitydense}{{4.2}{22}{Scale Factor Granularity}{table.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Rowwise (left), columnwise (middle) and scalar (right) scaling factor applied to weights of dense layers, with a scalar scaling factor — to biases. We observe optimal quantization for \( \lambda = 10\) in all cases. The values are averaged from the results of 5 training runs with different seeds.}}{23}{figure.caption.15}\protected@file@percent }
\newlabel{fig:pareto-mnist-unique-vals-accuracy}{{4.1}{23}{Rowwise (left), columnwise (middle) and scalar (right) scaling factor applied to weights of dense layers, with a scalar scaling factor — to biases. We observe optimal quantization for \( \lambda = 10\) in all cases. The values are averaged from the results of 5 training runs with different seeds}{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Rowwise scaling factors are applied to the weights of dense layers, while a scalar scaling factor is applied to the biases. Results are taken from the run with seed number 42.}}{23}{figure.caption.16}\protected@file@percent }
\newlabel{fig:quantization_results_1e-10_dense}{{4.2}{23}{Rowwise scaling factors are applied to the weights of dense layers, while a scalar scaling factor is applied to the biases. Results are taken from the run with seed number 42}{figure.caption.16}{}}
\BKM@entry{id=24,dest={73756273656374696F6E2E342E322E32},srcline={178}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304C5C303030615C303030795C303030655C303030725C30303073}
\BKM@entry{id=25,dest={73656374696F6E2E342E33},srcline={220}}{5C3337365C3337375C303030535C303030795C303030735C303030745C303030655C3030306D5C303030615C303030745C303030695C303030635C3030305C3034305C303030415C3030306E5C303030615C3030306C5C303030795C303030735C303030695C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030435C303030755C303030735C303030745C3030306F5C3030306D5C3030305C3034305C3030304C5C3030306F5C303030735C303030735C3030305C3034305C303030545C303030655C303030725C3030306D5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Rowwise (left), columnwise (middle) and scalar (right) scaling factor applied to weights of dense layers, with a scalar scaling factor — to biases. The values are averaged from the results of 5 training runs with different seeds.}}{24}{figure.caption.17}\protected@file@percent }
\newlabel{fig:pareto-mnist-range-accuracy}{{4.3}{24}{Rowwise (left), columnwise (middle) and scalar (right) scaling factor applied to weights of dense layers, with a scalar scaling factor — to biases. The values are averaged from the results of 5 training runs with different seeds}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Convolutional Layers}{24}{subsection.4.2.2}\protected@file@percent }
\newlabel{subsec:convolutionallayers}{{4.2.2}{24}{Convolutional Layers}{subsection.4.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Systematic Analysis of Custom Loss Terms}{24}{section.4.3}\protected@file@percent }
\newlabel{sec:dataset}{{4.3}{24}{Systematic Analysis of Custom Loss Terms}{section.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Rowwise (left), columnwise (middle) and scalar (right) scaling factor applied to weights of dense layers, with a scalar scaling factor — to biases. Results are taken from the run with seed number 42.}}{25}{figure.caption.18}\protected@file@percent }
\newlabel{fig:val-accs-over-epochs-dense}{{4.4}{25}{Rowwise (left), columnwise (middle) and scalar (right) scaling factor applied to weights of dense layers, with a scalar scaling factor — to biases. Results are taken from the run with seed number 42}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Rowwise (left), columnwise (middle) and scalar (right) scaling factor applied to weights of dense layers, with a scalar scaling factor — to biases. Results are taken from the run with seed number 42.}}{25}{figure.caption.19}\protected@file@percent }
\newlabel{fig:val-losses-over-epochs-dense}{{4.5}{25}{Rowwise (left), columnwise (middle) and scalar (right) scaling factor applied to weights of dense layers, with a scalar scaling factor — to biases. Results are taken from the run with seed number 42}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Channelwise (left), rowwise (middle) and columnwise (right) scaling factor applied to kernels of convolutional layers, with a scalar scaling factor — to biases. We observe optimal quantization for \( \lambda = 10\) in all cases. The values are averaged from the results of 5 training runs with different seeds.}}{26}{figure.caption.20}\protected@file@percent }
\newlabel{fig:pareto-mnist-unique-vals-accuracy}{{4.6}{26}{Channelwise (left), rowwise (middle) and columnwise (right) scaling factor applied to kernels of convolutional layers, with a scalar scaling factor — to biases. We observe optimal quantization for \( \lambda = 10\) in all cases. The values are averaged from the results of 5 training runs with different seeds}{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Channelwise (left), rowwise (middle) and columnwise (right) scaling factor applied to kernels of convolutional layers, with a scalar scaling factor — to biases. The values are averaged from the results of 5 training runs with different seeds.}}{26}{figure.caption.21}\protected@file@percent }
\newlabel{fig:pareto-mnist-range-accuracy}{{4.7}{26}{Channelwise (left), rowwise (middle) and columnwise (right) scaling factor applied to kernels of convolutional layers, with a scalar scaling factor — to biases. The values are averaged from the results of 5 training runs with different seeds}{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Channelwise scaling factors are applied to the kernels of convolutional layers, while a scalar scaling factor is applied to the biases. Results are taken from the run with seed number 42.}}{27}{figure.caption.22}\protected@file@percent }
\newlabel{fig:quantization_results_1e-10_dense}{{4.8}{27}{Channelwise scaling factors are applied to the kernels of convolutional layers, while a scalar scaling factor is applied to the biases. Results are taken from the run with seed number 42}{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Channelwise (left), rowwise (middle) and columnwise (right) scaling factor applied to kernels of dense layers, with a scalar scaling factor — to biases. Results are taken from the run with seed number 42.}}{28}{figure.caption.23}\protected@file@percent }
\newlabel{fig:val-accs-over-epochs-dense}{{4.9}{28}{Channelwise (left), rowwise (middle) and columnwise (right) scaling factor applied to kernels of dense layers, with a scalar scaling factor — to biases. Results are taken from the run with seed number 42}{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Channelwise (left), rowwise (middle) and columnwiselar (right) scaling factor applied to kernels of dense layers, with a scalar scaling factor — to biases. Results are taken from the run with seed number 42.}}{28}{figure.caption.24}\protected@file@percent }
\newlabel{fig:val-losses-over-epochs-dense}{{4.10}{28}{Channelwise (left), rowwise (middle) and columnwiselar (right) scaling factor applied to kernels of dense layers, with a scalar scaling factor — to biases. Results are taken from the run with seed number 42}{figure.caption.24}{}}
\BKM@entry{id=26,dest={636861707465722E35},srcline={1}}{5C3337365C3337375C303030525C303030655C3030306C5C303030615C303030745C303030655C303030645C3030305C3034305C303030575C3030306F5C303030725C3030306B}
\abx@aux@cite{0}{ott2016rnn}
\abx@aux@segm{0}{0}{ott2016rnn}
\abx@aux@cite{0}{rastegari2016xnor}
\abx@aux@segm{0}{0}{rastegari2016xnor}
\abx@aux@cite{0}{courbariaux2015binaryconnect}
\abx@aux@segm{0}{0}{courbariaux2015binaryconnect}
\abx@aux@cite{0}{yunchao2014compressing}
\abx@aux@segm{0}{0}{yunchao2014compressing}
\abx@aux@cite{0}{kim2021ibert}
\abx@aux@segm{0}{0}{kim2021ibert}
\abx@aux@cite{0}{krishnamoorthi2018quantizing}
\abx@aux@segm{0}{0}{krishnamoorthi2018quantizing}
\abx@aux@cite{0}{hubara2016qnn}
\abx@aux@segm{0}{0}{hubara2016qnn}
\abx@aux@cite{0}{polino2018modelcompression}
\abx@aux@segm{0}{0}{polino2018modelcompression}
\abx@aux@cite{0}{ott2016rnn}
\abx@aux@segm{0}{0}{ott2016rnn}
\abx@aux@cite{0}{rastegari2016xnor}
\abx@aux@segm{0}{0}{rastegari2016xnor}
\abx@aux@cite{0}{shuchang2016dorafenet}
\abx@aux@segm{0}{0}{shuchang2016dorafenet}
\abx@aux@cite{0}{Edouard2022SPIQ}
\abx@aux@segm{0}{0}{Edouard2022SPIQ}
\abx@aux@cite{0}{DBLP:conf/eccv/ZhangYYH18}
\abx@aux@segm{0}{0}{DBLP:conf/eccv/ZhangYYH18}
\abx@aux@cite{0}{shuchang2016dorafenet}
\abx@aux@segm{0}{0}{shuchang2016dorafenet}
\abx@aux@cite{0}{DBLP:conf/eccv/ZhangYYH18}
\abx@aux@segm{0}{0}{DBLP:conf/eccv/ZhangYYH18}
\abx@aux@cite{0}{courbariaux2015binaryconnect}
\abx@aux@segm{0}{0}{courbariaux2015binaryconnect}
\abx@aux@cite{0}{hubara2016qnn}
\abx@aux@segm{0}{0}{hubara2016qnn}
\abx@aux@cite{0}{rastegari2016xnor}
\abx@aux@segm{0}{0}{rastegari2016xnor}
\abx@aux@cite{0}{ott2016rnn}
\abx@aux@segm{0}{0}{ott2016rnn}
\abx@aux@cite{0}{soroosh2018adaptive}
\abx@aux@segm{0}{0}{soroosh2018adaptive}
\abx@aux@cite{0}{DBLP:conf/eccv/WangLGAC22}
\abx@aux@segm{0}{0}{DBLP:conf/eccv/WangLGAC22}
\abx@aux@cite{0}{DBLP:journals/ijcv/DongNLCSZ19}
\abx@aux@segm{0}{0}{DBLP:journals/ijcv/DongNLCSZ19}
\abx@aux@cite{0}{han2016deepcompression}
\abx@aux@segm{0}{0}{han2016deepcompression}
\abx@aux@cite{0}{polino2018modelcompression}
\abx@aux@segm{0}{0}{polino2018modelcompression}
\abx@aux@cite{0}{soroosh2018adaptive}
\abx@aux@segm{0}{0}{soroosh2018adaptive}
\abx@aux@cite{0}{DBLP:conf/eccv/WeiPQOY18}
\abx@aux@segm{0}{0}{DBLP:conf/eccv/WeiPQOY18}
\abx@aux@cite{0}{DBLP:journals/corr/abs-2003-00146}
\abx@aux@segm{0}{0}{DBLP:journals/corr/abs-2003-00146}
\abx@aux@cite{0}{DBLP:conf/aaai/TangH017}
\abx@aux@segm{0}{0}{DBLP:conf/aaai/TangH017}
\abx@aux@cite{0}{DBLP:conf/iclr/HouYK17}
\abx@aux@segm{0}{0}{DBLP:conf/iclr/HouYK17}
\abx@aux@cite{0}{yunchao2014compressing}
\abx@aux@segm{0}{0}{yunchao2014compressing}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Related Work}{29}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:chapter5}{{5}{29}{Related Work}{chapter.5}{}}
\BKM@entry{id=27,dest={636861707465722E36},srcline={1}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030635C3030306C5C303030755C303030735C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions}{31}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:chapter6}{{6}{31}{Conclusions}{chapter.6}{}}
\BKM@entry{id=28,dest={636861707465722A2E3235},srcline={84}}{5C3337365C3337375C303030425C303030695C303030625C3030306C5C303030695C3030306F5C303030675C303030725C303030615C303030705C303030685C30303079}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Bibliography}{33}{chapter*.25}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\abx@aux@read@bbl@mdfivesum{F3CDF0166C9DA387A34F4946F7585C6B}
\abx@aux@defaultrefcontext{0}{DBLP:conf/codit/KhalifaM24}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{bengio2013estimating}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:journals/jstsp/Chen0ZHY20}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{courbariaux2015binaryconnect}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:journals/ijcv/DongNLCSZ19}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:journals/corr/abs-2003-00146}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:conf/iclr/EsserMBAM20}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{fan2021training}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{gholami2021survey}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{yunchao2014compressing}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{gray1998quantization}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:journals/tnn/GyselPMG18}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{han2016deepcompression}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:journals/corr/HintonVD15}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:conf/iclr/HouYK17}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:journals/information/HowardG20}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{huang2017densely}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{hubara2016qnn}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{jacob2018quantization}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{jiang2021efficient}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:conf/cvpr/JungSLSHKHC19}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{soroosh2018adaptive}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:journals/corr/abs-2101-05615}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{kim2021ibert}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{krishnamoorthi2018quantizing}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{krizhevsky2009learning}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{lecun2010mnist}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:conf/nips/CunDS89}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:journals/corr/abs-2404-05639}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:conf/iclr/MolchanovTKAK17}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:journals/corr/abs-2105-13331}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:conf/icmlt/OkadoMIKS22}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{ott2016rnn}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:conf/eccv/ParkYV18}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{polino2018modelcompression}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{rastegari2016xnor}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:journals/csi/RegueroMV25}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:conf/aaai/TangH017}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:conf/eccv/WangLGAC22}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:conf/eccv/WeiPQOY18}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:journals/corr/abs-2111-00364}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{Edouard2022SPIQ}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{DBLP:conf/eccv/ZhangYYH18}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{shuchang2016dorafenet}{nty/global//global/global}
\global\@namedef{scr@dte@chapter@lastmaxnumwidth}{10.85587pt}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{18.26904pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{26.73907pt}
\@writefile{toc}{\providecommand\tocbasic@end@toc@file{}\tocbasic@end@toc@file}
\gdef \@abspage@last{47}
